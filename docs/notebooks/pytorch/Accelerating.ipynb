{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9dc10f-8ea5-482a-8e91-53b8436d3d4d",
   "metadata": {},
   "source": [
    "Gli autori ci informano sul fatto che è stato aggiunto il supporto alla sparsificazione semi strutturata (2:4) nella libreria PyTorch. Tale tipologia di sparisficazione consente di ottenere un incremento fino al 10% delle prestazioni di un modello durante l'inferenza per attività di segmentazione di immagini sostituendo la moltiplicazione fra matrici dense con la moltiplicazione fra matrici sparse. Le moltiplicazioni fra matrici intervengono sia nella fase di inferenza sia nella fase di training di reti neurali. Gli autori sostengono anche di essere riusciti, sviluppando le stesse primitive utilizzate per accelerare l'inferenza, a velocizzare il processo di addestramento di reti neurali. Si tratterebbe della prima implementazione di open source relativa all'accelerazione del processo di addestramento utilizzando il metodo della sparsificazione. L'API risultante è stata inglobata in torchao parte di PyTorch.\n",
    "\n",
    "L'idea generale sarebbe quella di saltare tutti quei calcoli che coinvolgano valori nulli all'interno dei tensori i quali, nel caso di reti neurali sparsificate, conterranno molti valori nulli con conseguente velocizzazione del processo di moltiplicazione fra matrici. La sparsificazione in se non porterebbe benefici in termini computazionali perché sebbene i tensori possano essere fortemente sparsificati (con moltissimi valori nulli, anche fino al 95-98% dei valori totali), le operazioni che vanno coinvolgendo valori nulli vanno comunque eseguite ed il tempo necessario alla loro esecuzione è lo stesso di quello relativo ad operazioni fra valori che non siano nulli. Il risultato di tutto ciò sarà stessa latenza e stessa occupazione di spazio. Per ottenere benefici reali sarà necessario bypassare i calcoli che coinvolgano i valori potati, cioè nulli.\n",
    "\n",
    "I nuovi kernel (ovvero funzioni ottimizzate per un dato task) per matrici sparse, rimuovono gli elementi potati dai calcoli e memorizzano i tensori usando un formato compresso. Esistono diversi formati di sparsificazione ma gli autori sono interessati principalmente ad un particolare tipo di sparsificazione semi strutturata che è quella 2:4 detta anche fine-grained structured sparsity o più generalmente N:M structured sparsity (cioè per ogni blocco di M elementi al più N devono essere diversi da zero)\n",
    "\n",
    "![2:4 sparse compressed representation](img\\2_4spaseRep.jpg)\n",
    "\n",
    "Una matrice 2:4 è una matrice in cui al più 2 elementi sono diversi da zero ogni 4 elementi. Questo tipo di sparsificazione semi strutturata porta a dei benefici in termini computazionali e di accuratezza. Infatti le GPU prodotte da NVIDIA offrono accelerazione hardware e librerie di supporto, come cuSPARSELt, che consentono di eseguire moltiplicazioni fra matrici fino ad 1,6 volte più rapidamente. Inoltre la sparsità 2:4 non porta l'accuratezza a degradarsi di più rispetto ad altri pattern e una fase di addestramento fatta dopo la sparsificazione consente di riaquisire gran parte dell'accuratezza eventualmente perduta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
