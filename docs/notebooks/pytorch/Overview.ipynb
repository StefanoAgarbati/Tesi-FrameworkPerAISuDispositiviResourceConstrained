{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbd2993-37eb-49a9-a178-35edbf9ff7cf",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "\n",
    "+ si tratta di una libreria per la gestione di tensori ottimizzata per applicazioni di deep learning eseguite su GPU o CPU\n",
    "+ altra definizione: framework open source per il machine learning\n",
    "    + piattaforma che consente di creare ed addestrare modelli di deep learning in maniera semplice\n",
    "+ molto utilizzato nella ricerca universitaria e non e nell'industria\n",
    "+ fornisce supporto ad un ampio insieme di casi di uso\n",
    "    + elaborazione del linguaggio naturale, computer vision, IA generativa ...\n",
    "+ è fortemente ottimizzato al fine di ottenere le migliori prestazioni possibili su CPU, GPU ed acceleratori harware dedicati\n",
    "+ rende possibile il deployment sia anche su dispositivi mobili o con risorse limitate\n",
    "+ supporta il training distribuito   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8f3ac1-9811-43b1-a09f-b5193b136064",
   "metadata": {},
   "source": [
    "+ in PyTorch esistono due primitive per lavorare con i dati torch.utils.data.DataLoader e torch.utils.data.Dataset.\n",
    "    + Dataset memorizza i vari campioni e le etichette corrispondenti\n",
    "    + Dataloader ritorna un oggetto iterabile che wrappa al suo interno il Dataset\n",
    "+ PyTorch consente di scaricare direttamente dalla rete alcuni dataset di riferimento\n",
    "    + possono essere scaricati separatamente l'insieme di training e l'insieme di test attraverso il parametro **train** della funzione factory utilizzata per ottenere un dataset specifico\n",
    "        + è un parametro boolean: se true otteniamo un dataset di training, se false otteniamo un dataset per il test del modello\n",
    "+ una volta ottenuti i due insiemi di training e di test possiamo creare due oggetti DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e3332c0-3947-4fc7-8712-8c9ebac9dc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python311\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\python311\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python311\\lib\\site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\python311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\python311\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\python311\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\python311\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a024791-61cc-4da7-8f69-7ff8c73d7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(root='data', train='true', download='true', transform=ToTensor())\n",
    "test_data = datasets.FashionMNIST(root='data', train='false', download='false', transform=ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d73ceca-c3ae-4ac3-b09a-b70c8f1d2297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataloader =  600\n",
      "Test dataloader = <torch.utils.data.dataloader.DataLoader object at 0x000001E31DD87550>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "training_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "print(f\"Training dataloader =  {len(training_dataloader)}\")\n",
    "print(f\"Test dataloader = {test_dataloader}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48444c-a282-4193-a257-788373cc00d5",
   "metadata": {},
   "source": [
    "+ una rete neurale può essere creata a partire dalla classe Module del package nn\n",
    "    + all'interno del costruttore __init__ si definisce la struttura della rete\n",
    "    + all'interno del metodo forward si deve descrivere come l'input deve attraversare la rete\n",
    "        + cioò come l'input deve essere elaborato dalla rete\n",
    "    + è possibile sfruttare degli acceleratori hardware (tipo cuda) se disponibili\n",
    "        + in loro mancanza si utilizzerà la CPU per eseguire i vari calcoli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7595ae-3683-48c1-bc27-453ee8cd1974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# controlliamo se ci sono acceleratori presenti\n",
    "torch.accelerator.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74933d34-4315-4df9-8d99-02ff291007ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: None\n"
     ]
    }
   ],
   "source": [
    "# possiamo chiedere a torch di restituirci l'acceleratore disponibile sotto forma di oggetto Device\n",
    "aDevice = torch.accelerator.current_accelerator()\n",
    "print(f\"Device: {aDevice}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41397f46-6c3a-4266-8f0a-e99ad48812bf",
   "metadata": {},
   "source": [
    "+ per l'addestramento di un modello abbiamo bisogno di una loss function e di un optimizer\n",
    "+ il modello viene addestrato usando mini batches\n",
    "    + un mini batches è un piccolo insieme di elementi del dataset di training\n",
    "    + quindi il dataset di training iniziale viene suddiviso in più mini batches\n",
    "    + ad ogni iterazione vengono valutati tutti gli elementi nel mini batch, calcolata la loss funcion e poi aggiornati i pesi utilizzando la backpropagation utilizzando il gradiente della funzione di perdita\n",
    "    + l'elaborazione di tutti i mini batches costituisce un'epoca (epoch)\n",
    "+ conclusa la fase di addestramento si verifica, attraverso l'insieme di test, se il modello abbia effettivamente appreso dai dati\n",
    "    + si possono utilizzare diverse metriche come ad esempio l'accuratezza (accuracy)\n",
    "        + dipende anche dal tipo di problema di learning ovvero classificazione, regressione ecc...\n",
    "        + l'accuracy per problemi di classificazione è definita come $Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "            + dove TP = true positive, TN = true negativi, FP = false positive, FN = false negative\n",
    "            + in pratica la frazione delle previsioni corrette sul totale dei dati elaborati\n",
    "+ generalmente l'addestramento considera diverse epoche e quindi il dataset di addestramento viene ripassato più volte\n",
    "    + ci si aspetta un aumento dell'accuratezza ed una diminuzione dell'errore medio alla fine di ogni epoca\n",
    "+ un modello, una volta addestrato, può essere salvato\n",
    "    + vengono salvati tutti i suoi parametri e non la sua struttura\n",
    "    + viene salvato soltanto il suo stato post addestramento\n",
    "+ i parametri salvati, ovvero lo stato di un modello, possono essere ricaricati dopo aver ricreato la struttura del modello\n",
    "    + esiste il metodo load_state_dict() della classe base Module usata per costruire la struttura del modello "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813db32b-9c9a-4963-9963-ef11aff0e666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
