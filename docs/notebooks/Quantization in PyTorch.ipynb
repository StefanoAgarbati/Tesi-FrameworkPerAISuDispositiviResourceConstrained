{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd39396-08c3-4cf0-b715-d57c0cd5f47f",
   "metadata": {},
   "source": [
    "### Quantizzazione in PyTorch\n",
    "\n",
    "+ quantizzazione\n",
    "    + tecnica di compressione per reti neurali\n",
    "    + consente di ridurre le dimensioni di una rete neurale profonda e di velocizzare la sua esecuzione\n",
    "        + meno memoria richiesta per memorizzare la rete\n",
    "        + meno tempo richiesto per inferire un risultato\n",
    "    + è una tecnica semplice ed economica dal punto di vista computazionale\n",
    "        + forse a significare che non sia richiesto troppo tempo per quantizzare un modello\n",
    "\n",
    "+ la quantizzazione, nell'ambito del deep learning, si riferisce alla riduzione della precisione numerica con cui vengono rappresentati i pesi e le attivazioni\n",
    "    + ad esempio si trasformano tutti i numeri rappresentati in formato float a 16 bit in interi ad 8 bit\n",
    "        + risparmio sicuro in termini di spazio\n",
    "        + ma anche perdita dell'accuratezza\n",
    "    + la perdita di precisione di un modello quantizzato può essere minima rispetto al modello di riferimento (cioè lo stesso modello ma non quantizzato)\n",
    "        + però si guadagna in termini di occupazione di memoria\n",
    "            + è richiesto uno spazio da 2 a 4 volte inferiore rispetto al rifermento\n",
    "        + ci si guadagna in termini di costo computazionale\n",
    "            + inferenze fino a 5 volte più veloci rispetto al modello di riferimento\n",
    "+ la quantizzazione porta quindi ad ottenere un modello più piccolo e che funziona in maniera più efficiente\n",
    "    + l'hardware moderno consente di eseguire operazioni su dati ad 8 bit più velocemente (rispetto a dati a 32 bit)\n",
    "        + ne risulta un throughput (numero di operazioni per unità di tempo) più elevato nel caso 8 bit\n",
    "    + un modello più piccolo richiede meno memoria e porta a consumi minori di energia\n",
    "        + quindi un modello più adatto ad essere eseguito su dispositivi con risorse limitate (resource-constrained)\n",
    "\n",
    "+ Mapping function\n",
    "    + si tratta di una funzione che ad ogni valore float fa corrispondere un valore intero ($Q \\colon \\mathbb{R} \\to \\mathbb{Z}$)\n",
    "    + viene comunemente ustilizzata la seguente funzione $Q(r) = round(r/S + Z)$\n",
    "        + r rappresenta il valore di input\n",
    "        + S e Z rappresentano i parametri di quantizzazione \n",
    "    + la riconversione di un valore intero (quantizzato) nel corrispondente valore float avviene per mezze della funzione seguente\n",
    "        + $\\tilde{r} = (Q(r) - Z) \\cdot S$\n",
    "        + in generale risulterà che $r \\ne \\tilde{r}$ e dunque che $r - \\tilde{r} \\ne 0$\n",
    "            + la differenza fra di essi (cioè $r - \\tilde{r}$) prende il nome di errore di quantizzazione\n",
    "\n",
    "+ Parametri di quantizzazione\n",
    "    + la funzione $Q(r)$ dipende da due parametri, quali S e Z, detti parametri di quantizzazione\n",
    "    + S prende il nome di fattore di scala (o scaling factor)\n",
    "        + definito come $S = \\frac{\\beta - \\alpha}{\\beta_q - \\alpha_q}$\n",
    "            + dove $[\\alpha, \\beta]$ è l'intervallo dei possibili valori di input (float) ed $[\\alpha_q, \\beta_q]$ è l'intervallo dei possibili valori discreti nello spazio quantizzato\n",
    "            + nel caso caso della quantizzazione ad 8 bit, per l'intervallo di uscita, si avrà $\\beta_q - \\alpha_q \\le (2^8 - 1)$  \n",
    "    + Z prende il nome di punto zero (o zero-point)\n",
    "        + serve a fare in modo che al valore 0 nello spazio dei valori di input (un intervallo di valori reali) corrisponda esattamento il valore 0 nello spazio dei valori discreti di uscita (lo spazio quantizzato)\n",
    "        + $Z = - \\left(\\frac{\\alpha}{S} - \\alpha_q \\right)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29069f06-907c-4b73-89df-db3167cecec9",
   "metadata": {},
   "source": [
    "**Processo di calibrazione per la stima dei valori S e Z da approfondire meglio**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
